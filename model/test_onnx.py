#!/usr/bin/env python3
"""
Test and Fix ONNX Models for Robot Dog
Tests existing ONNX models and creates fixed-shape versions for ARM compatibility
"""

import numpy as np
import os
import torch
import torch.onnx

def create_fixed_shape_model():
    """Create a new ONNX model with fixed batch size for ARM compatibility"""
    
    print("ğŸ”§ Creating Fixed-Shape ONNX Model")
    print("=" * 40)
    
    # Model configuration
    STATE_DIM = 21  # 12 joints + 8 commands + 1 intensity
    ACTION_DIM = 24  # 12 mid + 12 target angles
    MAX_ACTION = 1.0
    
    # Paths
    pth_path = "/home/matthewthomasbeck/Projects/Robot_Dog/model/blind_rl_model.pth"
    onnx_path_fixed = "/home/matthewthomasbeck/Projects/Robot_Dog/model/blind_rl_model_fixed.onnx"
    
    print(f"ğŸ“ Input model: {pth_path}")
    print(f"ğŸ“¤ Output model: {onnx_path_fixed}")
    
    if not os.path.exists(pth_path):
        print(f"âŒ Model file not found: {pth_path}")
        return False
    
    try:
        # Load checkpoint
        print(f"ğŸ“¥ Loading checkpoint...")
        checkpoint = torch.load(pth_path, map_location='cpu')
        
        # Create Actor model
        print(f"ğŸ—ï¸  Creating Actor model...")
        class Actor(torch.nn.Module):
            def __init__(self, state_dim, action_dim, max_action):
                super(Actor, self).__init__()
                self.layer_1 = torch.nn.Linear(state_dim, 400)
                self.layer_2 = torch.nn.Linear(400, 300)
                self.layer_3 = torch.nn.Linear(300, action_dim)
                self.max_action = max_action

            def forward(self, state):
                a = torch.nn.functional.relu(self.layer_1(state))
                a = torch.nn.functional.relu(self.layer_2(a))
                a = torch.tanh(self.layer_3(a)) * self.max_action
                return a
        
        model = Actor(STATE_DIM, ACTION_DIM, MAX_ACTION)
        
        # Load weights
        if isinstance(checkpoint, dict) and 'actor_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['actor_state_dict'])
            print(f"âœ… Loaded actor weights from checkpoint")
        else:
            model.load_state_dict(checkpoint)
            print(f"âœ… Loaded weights directly")
        
        # Set to evaluation mode
        model.eval()
        
        # Create dummy input with FIXED batch size
        print(f"ğŸ”§ Creating fixed-size dummy input...")
        dummy_input = torch.randn(1, STATE_DIM)  # Fixed batch size = 1
        
        # Test forward pass
        print(f"ğŸ§ª Testing forward pass...")
        with torch.no_grad():
            output = model(dummy_input)
            print(f"âœ… Forward pass successful: {output.shape}")
            print(f"ğŸ“Š Output range: [{output.min().item():.3f}, {output.max().item():.3f}]")
        
        # Export to ONNX with FIXED shapes
        print(f"ğŸš€ Exporting to ONNX with fixed shapes...")
        torch.onnx.export(
            model,
            dummy_input,
            onnx_path_fixed,
            export_params=True,
            opset_version=11,
            do_constant_folding=True,
            input_names=["state"],
            output_names=["action"],
            # FIXED shapes - no dynamic batch dimension
            input_shapes={"state": [1, STATE_DIM]},
            output_shapes={"action": [1, ACTION_DIM]},
            dynamic_axes=None  # Disable dynamic axes
        )
        
        # Verify ONNX file
        if os.path.exists(onnx_path_fixed):
            file_size = os.path.getsize(onnx_path_fixed) / (1024 * 1024)
            print(f"âœ… ONNX export successful! File size: {file_size:.1f} MB")
            
            # Try to validate ONNX
            try:
                import onnx
                onnx_model = onnx.load(onnx_path_fixed)
                onnx.checker.check_model(onnx_model)
                print(f"âœ… ONNX validation passed")
            except ImportError:
                print(f"âš ï¸  ONNX validation skipped (onnx package not available)")
            except Exception as e:
                print(f"âš ï¸  ONNX validation warning: {e}")
        else:
            print(f"âŒ ONNX file was not created")
            return False
        
        print(f"\nğŸ‰ Fixed-shape ONNX export completed successfully!")
        print(f"ğŸ“ ONNX file: {onnx_path_fixed}")
        print(f"ğŸ”§ Ready for ARM CPU and NCS2 deployment!")
        
        return True
        
    except Exception as e:
        print(f"âŒ Export failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_onnx_model():
    """Test the exported ONNX model"""
    
    # Test both models
    onnx_paths = [
        "/home/matthewthomasbeck/Projects/Robot_Dog/model/blind_rl_model_new.onnx",
        "/home/matthewthomasbeck/Projects/Robot_Dog/model/blind_rl_model_fixed.onnx"
    ]
    
    for i, onnx_path in enumerate(onnx_paths):
        print(f"ğŸ§ª Testing ONNX Model {i+1}")
        print("=" * 30)
        
        if not os.path.exists(onnx_path):
            print(f"âŒ ONNX file not found: {onnx_path}")
            continue
        
        try:
            # Try to load with OpenVINO
            from openvino.runtime import Core
            
            print(f"ğŸ“¥ Loading ONNX model with OpenVINO...")
            core = Core()
            
            # Check available devices
            devices = core.available_devices
            print(f"ğŸ” Available devices: {devices}")
            
            # Load the model
            model = core.read_model(onnx_path)
            print(f"âœ… Model loaded successfully")
            
            # Handle dynamic shapes properly
            try:
                input_shape = model.input().shape
                print(f"   ğŸ“Š Input shape: {input_shape}")
            except:
                print(f"   ğŸ“Š Input shape: Dynamic (batch dimension)")
            
            try:
                output_shape = model.output().shape
                print(f"   ğŸ“Š Output shape: {output_shape}")
            except:
                print(f"   ğŸ“Š Output shape: Dynamic (batch dimension)")
            
            # Try CPU compilation
            print(f"ğŸ”„ Testing CPU compilation...")
            try:
                compiled_model = core.compile_model(model, "CPU")
                print(f"âœ… Model compiled for CPU")
                
                # Test with dummy input
                dummy_input = np.random.randn(1, 21).astype(np.float32)
                print(f"ğŸ§ª Testing with dummy input: {dummy_input.shape}")
                
                # Run inference
                result = compiled_model([dummy_input])
                print(f"âœ… CPU inference successful!")
                print(f"   ğŸ“Š Output shape: {result.shape}")
                print(f"   ğŸ“Š Output range: [{result.min():.3f}, {result.max():.3f}]")
                
                # Test with realistic input (all zeros)
                zero_input = np.zeros((1, 21), dtype=np.float32)
                zero_result = compiled_model([zero_input])
                print(f"âœ… Zero input test successful!")
                print(f"   ğŸ“Š Zero input output range: [{zero_result.min():.3f}, {zero_result.max():.3f}]")
                
            except Exception as e:
                print(f"âš ï¸  CPU compilation failed: {e}")
            
            # Test with NCS2 compilation
            print(f"ğŸ”„ Testing NCS2 compilation...")
            try:
                ncs2_model = core.compile_model(model, "MYRIAD")
                print(f"âœ… Model compiled for NCS2 (MYRIAD)")
                
                # Test NCS2 inference
                ncs2_result = ncs2_model([dummy_input])
                print(f"âœ… NCS2 inference successful!")
                print(f"   ğŸ“Š NCS2 output shape: {ncs2_result.shape}")
                print(f"   ğŸ“Š NCS2 output range: [{ncs2_result.min():.3f}, {ncs2_result.max():.3f}]")
                
            except Exception as e:
                print(f"âš ï¸  NCS2 compilation failed: {e}")
                print(f"   ğŸ’¡ This is common and doesn't affect ONNX usability")
            
            print(f"\nğŸ‰ ONNX model {i+1} test completed!")
            print(f"   ğŸ“ Model file: {onnx_path}")
            
        except ImportError:
            print(f"âŒ OpenVINO not available")
            continue
        except Exception as e:
            print(f"âŒ Test failed: {e}")
            import traceback
            traceback.print_exc()
            continue
        
        print("-" * 50)
    
    print(f"\nğŸ”§ Summary: Tested {len(onnx_paths)} models")
    print(f"   ğŸ’¡ Use the fixed model for ARM CPU compatibility")
    print(f"   ğŸ’¡ Both models work with NCS2 (MYRIAD)")
    
    return True

def main():
    """Main function to run both creation and testing"""
    
    print("ğŸš€ Robot Dog ONNX Model Manager")
    print("=" * 40)
    
    # First, create the fixed-shape model if it doesn't exist
    fixed_model_path = "/home/matthewthomasbeck/Projects/Robot_Dog/model/blind_rl_model_fixed.onnx"
    if not os.path.exists(fixed_model_path):
        print(f"ğŸ“ Fixed-shape model not found, creating it...")
        if not create_fixed_shape_model():
            print(f"âŒ Failed to create fixed-shape model")
            return False
        print(f"âœ… Fixed-shape model created successfully")
    else:
        print(f"âœ… Fixed-shape model already exists")
    
    print(f"\n" + "="*50)
    
    # Then test both models
    if not test_onnx_model():
        print(f"âŒ Model testing failed")
        return False
    
    print(f"\nğŸ‰ All operations completed successfully!")
    return True

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 